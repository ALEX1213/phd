{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "import typing\n",
    "import collections\n",
    "\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets.github.scrape_repos import contentfiles\n",
    "from deeplearning.clgen import clgen\n",
    "from deeplearning.clgen import errors\n",
    "from deeplearning.clgen.corpuses import corpuses\n",
    "from deeplearning.clgen.proto import corpus_pb2\n",
    "from deeplearning.clgen.proto import clgen_pb2\n",
    "from deeplearning.clgen.proto import model_pb2\n",
    "from deeplearning.clgen.proto import sampler_pb2\n",
    "from labm8 import bazelutil\n",
    "from labm8 import pbutil\n",
    "from labm8 import viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 48 instances\n"
     ]
    }
   ],
   "source": [
    "instances_config = pathlib.Path('~/data/experimental/deeplearning/polyglot/instances.pbtxt').expanduser()\n",
    "instances = [\n",
    "    clgen.Instance(i) for i in\n",
    "    pbutil.FromFile(instances_config, clgen_pb2.Instances()).instance\n",
    "]\n",
    "print(\"Loaded {} instances\".format(len(instances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{PosixPath('/mnt/cc/data/datasets/github/corpuses/java'),\n",
       " PosixPath('/mnt/cc/data/datasets/github/corpuses/opencl')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetContentfileDirectories(instances: typing.List[clgen.Instance]) -> typing.List[pathlib.Path]:\n",
    "    \"\"\"Return the list of contentfiles directories.\"\"\"\n",
    "    preprocessed_dirs = {i.model.corpus.preprocessed.database_path.parent for i in instances}\n",
    "    contentfiles = {(p / 'contentfiles').resolve() for p in preprocessed_dirs}\n",
    "    return contentfiles\n",
    "\n",
    "GetContentfileDirectories(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/mnt/cc/data/datasets/github/repos_by_lang/opencl.db'),\n",
       " PosixPath('/mnt/cc/data/datasets/github/repos_by_lang/java.db')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GetContentfileDatabase(local_directory: pathlib.Path) -> pathlib.Path:\n",
    "    path = pathlib.Path(f'/mnt/cc/data/datasets/github/repos_by_lang/{local_directory.stem}.db')\n",
    "    if path.is_file():\n",
    "        return path\n",
    "    else:\n",
    "        raise FileNotFoundError(path)\n",
    "        \n",
    "contentfiles_dbs = [GetContentfileDatabase(p) for p in GetContentfileDirectories(instances)]\n",
    "contentfiles_dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450eb939e8> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450ebe8fd0> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450eb93828> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450eb52b00> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450eb93860> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f454e21c5c0> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450ebb5b00> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f454e21c710> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450eb2e080> ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (9779 of 9779) |####################| Elapsed Time: 0:05:47 Time:  0:05:47\n",
      "100% (283 of 283) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450eb9c9e8> ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10054 of 10054) |##################| Elapsed Time: 0:05:56 Time:  0:05:56\n",
      "100% (276 of 276) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450eb83e48> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f454e1eedd8> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f454e233b70> ... done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f454dd87dd8> ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10047 of 10047) |##################| Elapsed Time: 0:00:19 Time:  0:00:19\n",
      "100% (10047 of 10047) |##################| Elapsed Time: 0:00:16 Time:  0:00:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450ec223c8> ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10023 of 10023) |##################| Elapsed Time: 0:05:36 Time:  0:05:36\n",
      "100% (9950 of 9950) |####################| Elapsed Time: 0:00:19 Time:  0:00:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "<deeplearning.clgen.corpuses.corpuses.Corpus object at 0x7f450c266438> ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36% (3703 of 10011) |#######            | Elapsed Time: 0:00:46 ETA:   0:02:01"
     ]
    }
   ],
   "source": [
    "def GetOutputCorpus(instance: clgen.Instance) -> corpuses.Corpus:\n",
    "    with instance.Session():\n",
    "        out_dir = instance.model.SamplerCache(instance.sampler)\n",
    "        if not out_dir.is_dir():\n",
    "            return None\n",
    "        output_corpus_config = corpus_pb2.Corpus()\n",
    "        output_corpus_config.CopyFrom(instance.model.corpus.config)\n",
    "        output_corpus_config.local_directory = str(out_dir) + '.contentfiles'\n",
    "        if not pathlib.Path(output_corpus_config.local_directory).is_dir():\n",
    "            return None\n",
    "        corpus = corpuses.Corpus(output_corpus_config)\n",
    "        print(corpus, '... ', end='')\n",
    "        with instance.Session():\n",
    "            try:\n",
    "                corpus.Create()\n",
    "            except errors.EmptyCorpusException:\n",
    "                pass       \n",
    "        print('done')\n",
    "        return corpus\n",
    "\n",
    "output_corpuses = [GetOutputCorpus(i) for i in instances]\n",
    "print(\"Loaded {} output corpuses\".format(len([x for x in output_corpuses if x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InstanceStats(instance: clgen.Instance, output_corpus: corpuses.Corpus) -> typing.Dict[str, typing.Any]:\n",
    "    stats = collections.OrderedDict()\n",
    "    preprocessed_dir = instance.model.corpus.preprocessed.database_path.parent\n",
    "    language = (preprocessed_dir / 'contentfiles').resolve().name\n",
    "    stats['Language'] = {\n",
    "        'opencl': 'OpenCL',\n",
    "        'java': 'Java',\n",
    "    }[language]\n",
    "    stats['Encoding'] = 'Character' if 'Ascii' in str(instance.model.corpus.atomizer) else 'Token'\n",
    "    stats['Vocab size'] = instance.model.corpus.atomizer.vocab_size\n",
    "    stats['Corpus size'] = '{:.1f}M'.format(instance.model.corpus.encoded.token_count / 1e6)\n",
    "    # stats['Embedding'] = instance.model.config.architecture.embedding_size\n",
    "    stats['Model size'] = f'{instance.model.config.architecture.neurons_per_layer}x{instance.model.config.architecture.num_layers}'\n",
    "    # stats['Dropout'] = instance.model.config.architecture.post_layer_dropout_micros / 1e6\n",
    "    if instance.model.config.training.HasField('adam_optimizer'):\n",
    "        stats['Optimizer'] = 'Adam'\n",
    "        stats['Learning rate'] = instance.model.config.training.adam_optimizer.initial_learning_rate_micros / 1e6\n",
    "        stats['Decay'] = instance.model.config.training.adam_optimizer.learning_rate_decay_per_epoch_micros / 1e6\n",
    "    else:\n",
    "        stats['Optimizer'] = 'RMSProp'\n",
    "        stats['Learning rate'] = instance.model.config.training.rmsprop_optimizer.initial_learning_rate_micros / 1e6\n",
    "        stats['Decay'] = instance.model.config.training.rmsprop_optimizer.learning_rate_decay_per_epoch_micros / 1e6\n",
    "    telemetry = instance.model.TrainingTelemetry()\n",
    "    if telemetry:\n",
    "        stats['Epochs'] = len(telemetry)\n",
    "        stats['Final Loss'] = '{:.3f}'.format(telemetry[-1].loss)\n",
    "        stats['Training time'] = humanize.naturaldelta(\n",
    "            datetime.timedelta(seconds=sum(t.epoch_wall_time_ms for t in telemetry) / 1e3))\n",
    "        stats['Time / epoch'] = humanize.naturaldelta(\n",
    "            datetime.timedelta(seconds=np.array([t.epoch_wall_time_ms for t in telemetry]).mean() / 1e3))\n",
    "\n",
    "    if output_corpus:\n",
    "        samples_dir = instance.model.SamplerCache(instance.sampler)\n",
    "        sample_times = np.array([\n",
    "            pbutil.FromFile(samples_dir / f, model_pb2.Sample, uninitialized_okay=True).wall_time_ms for f in samples_dir.iterdir()\n",
    "        ], dtype=np.int32)\n",
    "        # TODO(cec): Use the number of extracted kernels, not the number of samples themselves.\n",
    "        # Sample times is in milliseconds, and we want time per thousand, so they cancel out.\n",
    "        # Average sample time in seconds.\n",
    "        sample_time_seconds = sample_times.mean() / 1000\n",
    "        stats['Sample temperature'] = humanize.intcomma(instance.sampler.temperature)\n",
    "        # stats['Output samples'] = humanize.intcomma(output_corpus.preprocessed.input_size)\n",
    "        stats['Output vocab size'] = humanize.intcomma(output_corpus.vocab_size)\n",
    "        stats['Time / sample (ms)'] = int(round(sample_times.mean()))\n",
    "        sample_throughput = (24 * 3600) / sample_time_seconds\n",
    "        stats['Samples / day'] = '{:.1f}k'.format(sample_throughput / 1000)\n",
    "        # stats['Time / 1k samples'] = humanize.naturaldelta(\n",
    "        #     datetime.timedelta(seconds=samples_time_seconds * 1000))\n",
    "        if output_corpus.preprocessed.size:\n",
    "            efficiency = (output_corpus.preprocessed.size / \n",
    "                          (output_corpus.preprocessed.input_size or 1))\n",
    "            good_sample_throughput = efficiency * sample_throughput\n",
    "            stats['Efficiency'] = '{:.2%}'.format(efficiency)\n",
    "            stats['Throughput / day'] = '{:.1f}k'.format(good_sample_throughput / 1000)\n",
    "    print(stats)\n",
    "    return stats\n",
    "\n",
    "stats = pd.DataFrame([InstanceStats(i, o) for i, o in zip(instances, output_corpuses)]).fillna('-')\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (_, row), instance in zip(stats.iterrows(), instances):\n",
    "    plt.plot([t.epoch_num for t in instance.model.TrainingTelemetry()], \n",
    "             [t.loss for t in instance.model.TrainingTelemetry()], \n",
    "             label=f\"{row['Language']}-{row['Model size']}\")\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.title('Training Losses')\n",
    "\n",
    "# X axis.\n",
    "# plt.xlim((0, 50 - 1))\n",
    "# ax.set_xticklabels([i + 1 for i in ax.get_xticks()])\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "# Y axis.\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "viz.finalise(size=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
