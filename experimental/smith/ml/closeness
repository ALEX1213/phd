#!/usr/bin/env python3
#
# TODO: Line style http://matplotlib.org/examples/lines_bars_and_markers/line_styles_reference.html
#
from math import sqrt

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy
import seaborn as sns
from phd.lib.labm8 import fs
from phd.lib.labm8 import math as labmath
from phd.lib.labm8 import viz
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import normalize


# Seaborn configuration:
sns.set(style="ticks", color_codes=True)
plt.style.use(["seaborn-white", "seaborn-paper"])


def get_cgo13_features(D):
  return np.array([
    (D["transfer"].values / (D["comp"].values + D["mem"].values)),
    (D["coalesced"].values / D["mem"].values),
    ((D["localmem"].values / D["mem"].values) * D["wgsize"].values),
    (D["comp"].values / D["mem"].values),
  ]).T


def get_raw_features(D):
  return np.array([
    D["comp"].values,
    D["rational"].values,
    D["mem"].values,
    D["localmem"].values,
    D["coalesced"].values,
    D["atomic"].values,
    D["transfer"].values,
    D["wgsize"].values,
  ]).T


def get_our_features(D):
  return np.array([
    D["comp"].values,
    D["rational"].values,
    D["mem"].values,
    D["localmem"].values,
    D["coalesced"].values,
    D["transfer"].values,
    D["wgsize"].values,
    (D["transfer"].values / (D["comp"].values + D["mem"].values)),
    (D["coalesced"].values / D["mem"].values),
    ((D["localmem"].values / D["mem"].values) * D["wgsize"].values),
    (D["comp"].values / D["mem"].values),
  ]).T


def get_static_features(D):
  return np.array([
    D["comp"].values,
    # D["rational"].values,
    D["mem"].values,
    D["localmem"].values,
    D["coalesced"].values,
    # D["F2:coalesced/mem"].values,
    # D["F4:comp/mem"].values,
  ], dtype=float).T


def get_labels(D):
  return D["oracle"]


def normalize(*args):
  # num_features = len(args[0][0])
  # print(num_features, "features")
  # for feature_idx in range(num_features):
  #     divisor = max([np.max(arg[:,feature_idx]) for arg in args])
  #     # divisor = max(np.median([np.median(arg[:,feature_idx]) for arg in args]), 1)
  #     print("Feature", feature_idx, "max:", divisor)

  #     for arg in args:
  #         arg[:,feature_idx] /= divisor

  # # Sanity-check that normalization worked:
  # for j in range(num_features):
  #     for arg in args:
  #         for i in arg[:,j]:
  #             assert(i <= 1)
  #             assert(i >= 0)

  return args


def closeness(platform_id):
  # Load datasets
  B = pd.read_csv("data/{}/benchmarks.csv".format(platform_id.lower()))
  B["synthetic"] = np.zeros(len(B))
  S = pd.read_csv("data/{}/synthetics.csv".format(platform_id.lower()))
  S["synthetic"] = np.ones(len(S))
  BS = pd.concat((B, S), ignore_index=True)

  features = get_cgo13_features
  # features = get_static_features

  # Transform to feature space:
  X1 = features(B)
  X2 = features(S)
  X3 = features(BS)

  ytest2 = get_labels(S)
  ytest3 = get_labels(BS)

  # Neighbours to check for:
  Xtest = features(B)
  ytest = get_labels(B)

  # Get nearest neighbours for kernels:
  nbrs = NearestNeighbors(n_neighbors=2, algorithm='brute').fit(X1)
  distances1, indices1 = nbrs.kneighbors(Xtest)

  nbrs = NearestNeighbors(n_neighbors=1, algorithm='brute').fit(X2)
  distances2, indices2 = nbrs.kneighbors(Xtest)

  nbrs = NearestNeighbors(n_neighbors=2, algorithm='brute').fit(X3)
  distances3, indices3 = nbrs.kneighbors(Xtest)

  # Find out whether the nearest neighbours have the same behaviour:
  behaviour1 = np.ones(len(indices1), dtype=bool)
  behaviour2 = np.ones(len(indices2), dtype=bool)
  behaviour3 = np.ones(len(indices3), dtype=bool)

  assert (len(distances1) == len(distances2))
  assert (len(distances2) == len(distances3))

  for i, index in enumerate(indices1):
    # index[0] is index of origin, index[1] is nearest neighbour:
    if index[1] == i:
      index[0], index[1] = index[1], index[0]
    if ytest[index[0]] != ytest[index[1]]:
      behaviour1[i] = False

  for i, index in enumerate(indices2):
    if ytest[i] != ytest2[int(index)]:
      behaviour2[i] = False

  for i, index in enumerate(indices3):
    # index[0] is index of origin, index[1] is nearest neighbour:
    if index[1] == i:
      index[0], index[1] = index[1], index[0]
    if ytest[index[0]] != ytest3[index[1]]:
      behaviour3[i] = False

  synthetic_neighbours3 = [BS.loc[i[1]]["synthetic"] for i in indices3]
  synthetic_distances3 = [
    d[1] for d, s in zip(distances3, synthetic_neighbours3) if s
  ]

  # USED TO IDENTIFY KERNELS WITH THE SAME FEATURES BUT DIFFERENT BEHAVIOUR:
  #
  # print()
  # print("Zero feature distance, different behaviour:")
  # for i,row in enumerate(zip(distances1, behaviour1)):
  #     distance, behaviour = row
  #     if distance[1] == 0 and not behaviour:
  #         print(" ",
  #               B.loc[indices1[i][0]]["benchmark"],
  #               B.loc[indices1[i][1]]["benchmark"])
  # print()

  # print()
  # print("Zero feature distance, different behaviour:")
  # for i,row in enumerate(zip(distances2, behaviour2)):
  #     distance, behaviour = row
  #     if distance == 0  and not behaviour:
  #         print(" ",
  #               B.loc[indices1[i][0]]["benchmark"],
  #               S.loc[indices1[i][1]]["benchmark"])
  # print()

  print()
  print("Closeness on Platform {}".format(platform_id.upper()))
  print("  Benchmarks:")
  print("  Median dist to nearest neighbour:     {:.1f}"
        .format(labmath.median(distances1[:, 1])))
  print("  Mean dist to nearest neighbour:       {:.1f}"
        .format(labmath.mean(distances1[:, 1])))
  print("  Nearest Neighbour has same behaviour: {:.1f} %"
        .format((sum(behaviour1) / len(behaviour1)) * 100))
  print()
  print("  Synthetics:")
  print("  Median dist to nearest neighbour:     {:.1f}"
        .format(labmath.median(distances2[:, 0])))
  print("  Mean dist to nearest neighbour:       {:.1f}"
        .format(labmath.mean(distances2[:, 0])))
  print("  Nearest Neighbour has same behaviour: {:.1f} %"
        .format((sum(behaviour2) / len(behaviour2)) * 100))
  print("  Closest neighbour:                    {:.1f}"
        .format(min(distances2[:, 0])))
  print()
  print("  Benchmarks w. synthetics:")
  print("  Median dist to nearest neighbour:     {:.1f}"
        .format(labmath.median(distances3[:, 1])))
  print("  Mean dist to nearest neighbour:       {:.1f}"
        .format(labmath.mean(distances3[:, 1])))
  print("  Median dist to synthetic neighbour:   {:.1f}"
        .format(labmath.median(synthetic_distances3)))
  print("  Nearest Neighbour has same behaviour: {:.1f} %"
        .format((sum(behaviour3) / len(behaviour3)) * 100))
  print("  Closer neighbours:                    {} {:.1f} %"
        .format(int(sum(synthetic_neighbours3)),
                (sum(synthetic_neighbours3) / len(B)) * 100))
  print("  Closest synthetic neighbour:          {:.1f}"
        .format(min(synthetic_neighbours3)))
  print("  Median dist to nearest synthetic:     {:.1f}"
        .format(labmath.median(synthetic_neighbours3)))
  print("  Farthest synthetic neighbour:         {:.1f}"
        .format(max(synthetic_neighbours3)))
  print()

  # def distplot(D):
  #     opts = {"kde": False, "bins": 25}
  #     ax = sns.distplot(D["distance"], **opts)
  #     ax.set_yscale("log", nonposy='clip')
  #     plt.ylim(0, 1000)
  #     plt.xlabel("")
  #     plt.ylabel("Count")

  MAXDIST = 1000
  benchmarks = pd.DataFrame(
      [(d, b) for d, b in zip(distances1[:, 1], behaviour1)
       if d < MAXDIST],
      columns=["distance", "behaviour"])
  synthetics = pd.DataFrame(
      [(d, b) for d, b in zip(distances3[:, 1], behaviour2) if d < MAXDIST],
      columns=["distance", "behaviour"])

  # plt.subplot(2, 2, 1)
  # distplot(benchmarks[benchmarks["behaviour"] == 1])
  # plt.title("B, same behaviour")

  # plt.subplot(2, 2, 3)
  # distplot(benchmarks[benchmarks["behaviour"] == 0])
  # plt.title("B, different behaviour")

  # plt.subplot(2, 2, 2)
  # distplot(synthetics[synthetics["behaviour"] == 1])
  # plt.title("BS, same behaviour")

  # plt.subplot(2, 2, 4)
  # distplot(synthetics[synthetics["behaviour"] == 0])
  # plt.title("BS, different behaviour")

  # plt.show()


def get_nearest_neighbour_distance(F1, F2):
  """
  Return nearest-neighbour distances from F1 to F2.
  """
  nbrs = NearestNeighbors(n_neighbors=1, algorithm='brute').fit(F2)
  distances, indices = nbrs.kneighbors(F1)
  # for d,i,f in zip(distances,indices,F1):
  #     if d == 0:
  #         print("distance: ", d, "clgen:", F2[i], "target:", f)
  return distances


def remove_duplicates(g):
  uniq = set()
  out = []
  for row in g.to_dict('records'):
    key = (row['benchmark'])

    if key not in uniq:
      out.append(row)
      uniq.add(key)

  g = pd.DataFrame(out)
  return g


def static_kernel_closeness():
  features = get_static_features

  # Set a seed for reproducible results:
  np.random.seed(204)

  # Load datasets:
  Benchmarks = pd.read_csv("data/a/benchmarks.csv")
  CLgen = pd.read_csv(
      fs.path("~/kernels/clgen/features.csv"))
  GitHub = pd.read_csv(
      fs.path("~/kernels/github/features.csv"))
  CLSmith = pd.read_csv(
      fs.path("~/kernels/clsmith/features.csv"))

  # Extract features:
  BenchmarksFeatures = features(remove_duplicates(Benchmarks))
  CLgenFeatures = features(CLgen)
  GitHubFeatures = features(GitHub)
  CLSmithFeatures = features(CLSmith)

  BenchmarksFeatures, CLgenFeatures, GitHubFeatures, CLSmithFeatures = normalize(
      BenchmarksFeatures, CLgenFeatures, GitHubFeatures, CLSmithFeatures)

  stepMax = max(
      len(GitHubFeatures), len(CLgenFeatures), len(CLSmithFeatures))

  LOG_SCALE = True
  if LOG_SCALE:
    stepMin = 10
    steps = np.array(list(exp_range(stepMin, stepMax, 1.5)), dtype=np.int32)
  else:
    stepMin = 100
    steps = np.array(list(range(stepMin, stepMax, 2500)), dtype=np.int32)

  GitHubSteps = [n for n in steps if n <= len(GitHubFeatures)]
  CLSmithSteps = [n for n in steps if n <= len(CLSmithFeatures)]
  CLgenSteps = [n for n in steps if n <= len(CLgenFeatures)]

  numGitHubSteps = len(GitHubSteps)
  numCLSmithSteps = len(CLSmithSteps)
  numCLgenSteps = len(CLgenSteps)

  print("#. GitHub kernels", GitHubSteps[-1])
  print("#. CLSmith kernels", CLSmithSteps[-1])
  print("#. CLgen kernels", CLgenSteps[-1])

  summarize_distance = np.median
  summarize_results = np.mean

  def error(x):
    scale = np.std(x) / sqrt(len(x))
    mean = np.mean(x)
    ci = scipy.stats.norm.interval(.95, loc=mean, scale=scale)
    return ci[1] - mean

  print("Steps:", steps)

  datasets = [
    {
      "name": "GitHub",
      "color": "b",
      "linestyle": ":",
      "steps": GitHubSteps,
      "features": GitHubFeatures,
      "distances": np.zeros(numGitHubSteps, dtype=float),
      "errors": np.zeros(numGitHubSteps, dtype=float)
    },
    {
      "name": "CLSmith",
      "color": "r",
      "linestyle": "--",
      "steps": CLSmithSteps,
      "features": CLSmithFeatures,
      "distances": np.zeros(numCLSmithSteps, dtype=float),
      "errors": np.zeros(numCLSmithSteps, dtype=float)
    },
    {
      "name": "CLgen",
      "color": "g",
      "linestyle": "-",
      "steps": CLgenSteps,
      "features": CLgenFeatures,
      "distances": np.zeros(numCLgenSteps, dtype=float),
      "errors": np.zeros(numCLgenSteps, dtype=float)
    },
  ]

  # Ratio improvements:
  GitHubDistances = get_nearest_neighbour_distance(BenchmarksFeatures,
                                                   GitHubFeatures)
  CLSmithDistances = get_nearest_neighbour_distance(BenchmarksFeatures,
                                                    CLSmithFeatures)
  CLgenDistances = get_nearest_neighbour_distance(BenchmarksFeatures,
                                                  CLgenFeatures)
  CLSmithCloser = [True if y < x else False for x, y in
                   zip(CLSmithDistances, CLgenDistances)]
  CLgenCloser = [True if y < x else False for x, y in
                 zip(GitHubDistances, CLgenDistances)]
  print("Closer CLSmith features:  {} ({:.1f} %)"
        .format(sum(CLSmithCloser),
                (sum(CLSmithCloser) / len(CLSmithCloser)) * 100))
  print("Closer CLgen features:  {} ({:.1f} %)"
        .format(sum(CLgenCloser), (sum(CLgenCloser) / len(CLgenCloser)) * 100))

  numIterations = 30
  # numIterations = 30

  for dataset in datasets:
    for i, n in enumerate(dataset["steps"]):
      numSteps = len(dataset["steps"])
      print("\r", dataset["name"], i + 1, "of", numSteps, end="")
      r = np.zeros(numIterations, dtype=float)
      for j in range(numIterations):
        np.random.shuffle(dataset["features"])
        r[j] = summarize_distance(get_nearest_neighbour_distance(
            BenchmarksFeatures, dataset["features"][:n]
        ))
      dataset["distances"][i] = summarize_results(r)
      dataset["errors"][i] = error(r)
    print("\nMin value of", dataset["name"], "with", dataset["steps"][-1],
          "kernels = {:.2f}".format(dataset["distances"][-1]))
    plt.errorbar(dataset["steps"], dataset["distances"],
                 yerr=dataset["errors"], c=dataset["color"],
                 linestyle=dataset["linestyle"],
                 label=dataset["name"], ecolor="k", capthick=1)
  ax = plt.gca()

  # No legend title
  plt.legend(loc='upper right')
  ax.get_legend().set_title("")
  ax.get_legend().draw_frame(True)

  plt.xlim(stepMin, stepMax)
  plt.ylim(0, )

  if LOG_SCALE:
    ax.set_xscale("log", nonposy='clip')

  plt.xlabel("#. OpenCL kernels")
  plt.ylabel("Feature Distance")

  figsize = (4.5, 2.15)
  viz.finalise(fs.path("~/cgo17/img/closeness.pdf"), figsize=figsize)


def zero_distance():
  features = get_static_features

  # Set a seed for reproducible results:
  np.random.seed(204)

  # Load datasets:
  Benchmarks = pd.read_csv("data/a/benchmarks.csv")
  CLgen = pd.read_csv(
      fs.path("~/kernels/clgen/features.csv"))
  GitHub = pd.read_csv(
      fs.path("~/kernels/github/features.csv"))
  CLSmith = pd.read_csv(
      fs.path("~/kernels/clsmith/features.csv"))

  # Extract features:
  BenchmarksFeatures = features(remove_duplicates(Benchmarks))
  CLgenFeatures = features(CLgen)
  GitHubFeatures = features(GitHub)
  CLSmithFeatures = features(CLSmith)

  BenchmarksFeatures, CLgenFeatures, GitHubFeatures, CLSmithFeatures = normalize(
      BenchmarksFeatures, CLgenFeatures, GitHubFeatures, CLSmithFeatures)

  # stepMax = max(
  #     len(GitHubFeatures), len(CLgenFeatures), len(CLSmithFeatures))
  stepMin = 0
  stepMax = 10000
  linStepSize = int((stepMax - stepMin) / 20)
  closeness_threshold = 0

  LOG_SCALE = False
  steps = np.array(list(range(stepMin, stepMax + linStepSize, linStepSize)),
                   dtype=np.int32)
  steps[0] = max(steps[0], 1)

  GitHubSteps = [n for n in steps if n <= len(GitHubFeatures)]
  CLSmithSteps = [n for n in steps if n <= len(CLSmithFeatures)]
  CLgenSteps = [n for n in steps if n <= len(CLgenFeatures)]

  numGitHubSteps = len(GitHubSteps)
  numCLSmithSteps = len(CLSmithSteps)
  numCLgenSteps = len(CLgenSteps)

  print("#. GitHub kernels", GitHubSteps[-1])
  print("#. CLSmith kernels", CLSmithSteps[-1])
  print("#. CLgen kernels", CLgenSteps[-1])

  # Zero-distance
  def summarize_distance(distances):
    return sum([1 if d <= closeness_threshold else 0 for d in distances])

  summarize_results = np.mean
  error = np.std
  # def error(x):
  #     scale = np.std(x) / sqrt(len(x))
  #     mean = np.mean(x)
  #     ci = scipy.stats.norm.interval(.95, loc=mean, scale=scale)
  #     return ci[1] - mean

  print("Steps:", steps)

  datasets = [
    {
      "name": "GitHub",
      "color": "b",
      "linestyle": ":",
      "steps": GitHubSteps,
      "features": GitHubFeatures,
      "distances": np.zeros(numGitHubSteps, dtype=float),
      "errors": np.zeros(numGitHubSteps, dtype=float)
    },
    {
      "name": "CLSmith",
      "color": "r",
      "linestyle": "--",
      "steps": CLSmithSteps,
      "features": CLSmithFeatures,
      "distances": np.zeros(numCLSmithSteps, dtype=float),
      "errors": np.zeros(numCLSmithSteps, dtype=float)
    },
    {
      "name": "CLgen",
      "color": "g",
      "linestyle": "-",
      "steps": CLgenSteps,
      "features": CLgenFeatures,
      "distances": np.zeros(numCLgenSteps, dtype=float),
      "errors": np.zeros(numCLgenSteps, dtype=float)
    },
  ]

  numIterations = 10

  # Plot an oracle line:
  # plt.plot(datasets[2]["steps"], datasets[2]["steps"],
  #          label="Oracle", color="k", linestyle="--")

  for dataset in datasets:
    for i, n in enumerate(dataset["steps"]):
      numSteps = len(dataset["steps"])
      print("\r", dataset["name"], i + 1, "of", numSteps, end="")
      r = np.zeros(numIterations, dtype=float)
      for j in range(numIterations):
        np.random.shuffle(dataset["features"])
        r[j] = summarize_distance(get_nearest_neighbour_distance(
            dataset["features"][:n], BenchmarksFeatures
        ))
      dataset["distances"][i] = summarize_results(r)
      dataset["errors"][i] = error(r)
    print("\nMin value of", dataset["name"], "with", dataset["steps"][-1],
          "kernels = {:.2f}".format(dataset["distances"][-1]))
    plt.errorbar(dataset["steps"], dataset["distances"],
                 yerr=dataset["errors"], c=dataset["color"],
                 linestyle=dataset["linestyle"],
                 label=dataset["name"], ecolor="k", capthick=1)
  ax = plt.gca()

  # No legend title
  plt.legend(loc='upper left')
  ax.get_legend().set_title("")
  ax.get_legend().draw_frame(True)

  plt.xlim(stepMin, stepMax)
  plt.ylim(-50, )

  if LOG_SCALE:
    ax.set_xscale("log", nonposy='clip')

  plt.xlabel("#. kernels")
  plt.ylabel("#. matches")

  figsize = (4.5, 2.0)
  viz.finalise(fs.path("~/cgo17/img/closeness.pdf"), figsize=figsize)


def closer_than():
  features = get_static_features

  # Set a seed for reproducible results:
  np.random.seed(204)

  # Load datasets:
  Benchmarks = pd.read_csv("data/a/benchmarks.csv")
  CLgen = pd.read_csv(
      fs.path("~/kernels/clgen/features.csv"))
  GitHub = pd.read_csv(
      fs.path("~/kernels/github/features.csv"))
  CLSmith = pd.read_csv(
      fs.path("~/kernels/clsmith/features.csv"))

  # Extract features:
  BenchmarksFeatures = features(remove_duplicates(Benchmarks))
  CLgenFeatures = features(CLgen)
  GitHubFeatures = features(GitHub)
  CLSmithFeatures = features(CLSmith)

  BenchmarksFeatures, CLgenFeatures, GitHubFeatures, CLSmithFeatures = normalize(
      BenchmarksFeatures, CLgenFeatures, GitHubFeatures, CLSmithFeatures)

  stepMax = max(
      len(GitHubFeatures), len(CLgenFeatures), len(CLSmithFeatures))

  LOG_SCALE = True
  if LOG_SCALE:
    stepMin = 10
    steps = np.array(list(exp_range(stepMin, stepMax, 2)), dtype=np.int32)
  else:
    stepMin = 100
    steps = np.array(list(range(stepMin, stepMax, 2500)), dtype=np.int32)

  GitHubSteps = [n for n in steps if n <= len(GitHubFeatures)]
  CLSmithSteps = [n for n in steps if n <= len(CLSmithFeatures)]
  CLgenSteps = [n for n in steps if n <= len(CLgenFeatures)]

  numGitHubSteps = len(GitHubSteps)
  numCLSmithSteps = len(CLSmithSteps)
  numCLgenSteps = len(CLgenSteps)

  print("#. GitHub kernels", GitHubSteps[-1])
  print("#. CLSmith kernels", CLSmithSteps[-1])
  print("#. CLgen kernels", CLgenSteps[-1])

  # summarize_distance = np.median

  # Zero-distance
  def summarize_distance(distances, notzero):
    if notzero:
      return sum([1 if d < 5 and d > 0 else 0 for d in distances])
    else:
      return sum([1 if d < 5 else 0 for d in distances])

  summarize_results = np.mean

  def error(x):
    scale = np.std(x) / sqrt(len(x))
    mean = np.mean(x)
    ci = scipy.stats.norm.interval(.95, loc=mean, scale=scale)
    return ci[1] - mean

  print("Steps:", steps)

  datasets = [
    {
      "name": "GitHub",
      "color": "b",
      "linestyle": ":",
      "steps": GitHubSteps,
      "features": GitHubFeatures,
      "distances": np.zeros(numGitHubSteps, dtype=float),
      "errors": np.zeros(numGitHubSteps, dtype=float)
    },
    {
      "name": "CLSmith",
      "color": "r",
      "linestyle": "--",
      "steps": CLSmithSteps,
      "features": CLSmithFeatures,
      "distances": np.zeros(numCLSmithSteps, dtype=float),
      "errors": np.zeros(numCLSmithSteps, dtype=float)
    },
    {
      "name": "CLgen",
      "color": "g",
      "linestyle": "-",
      "steps": CLgenSteps,
      "features": CLgenFeatures,
      "distances": np.zeros(numCLgenSteps, dtype=float),
      "errors": np.zeros(numCLgenSteps, dtype=float)
    },
  ]

  # Ratio improvements:
  GitHubDistances = get_nearest_neighbour_distance(BenchmarksFeatures,
                                                   GitHubFeatures)
  CLSmithDistances = get_nearest_neighbour_distance(BenchmarksFeatures,
                                                    CLSmithFeatures)
  CLgenDistances = get_nearest_neighbour_distance(BenchmarksFeatures,
                                                  CLgenFeatures)
  CLSmithCloser = [True if y < x else False for x, y in
                   zip(CLSmithDistances, CLgenDistances)]
  CLgenCloser = [True if y < x else False for x, y in
                 zip(GitHubDistances, CLgenDistances)]
  print("Closer CLSmith features:  {} ({:.1f} %)"
        .format(sum(CLSmithCloser),
                (sum(CLSmithCloser) / len(CLSmithCloser)) * 100))
  print("Closer CLgen features:  {} ({:.1f} %)"
        .format(sum(CLgenCloser), (sum(CLgenCloser) / len(CLgenCloser)) * 100))

  numIterations = 10
  # numIterations = 30

  # for i, row in enumerate(zip_longest(*[d["steps"] for d in datasets])):
  #     print(row)

  GitHub = datasets[0]
  CLSmith = datasets[1]
  CLgen = datasets[2]
  for i, n in enumerate(GitHub["steps"]):
    r = np.zeros(numIterations, dtype=float)
    for j in range(numIterations):
      np.random.shuffle(GitHub["features"])
      np.random.shuffle(CLSmith["features"])
      np.random.shuffle(CLgen["features"])

      GitHubDistances = get_nearest_neighbour_distance(
          BenchmarksFeatures, GitHub["features"][:n]
      )
      CLSmithDistances = get_nearest_neighbour_distance(
          BenchmarksFeatures, CLSmith["features"][:n]
      )
      CLgenDistances = get_nearest_neighbour_distance(
          BenchmarksFeatures, CLgen["features"][:n]
      )

  #         r[j] = summarize_distance()
  #         dataset["distances"][i] = summarize_results(r)
  #         dataset["errors"][i] = error(r)
  #     print("\nMin value of", dataset["name"], "with", dataset["steps"][-1],
  #           "kernels = {:.2f}".format(dataset["distances"][-1]))
  #     plt.errorbar(dataset["steps"], dataset["distances"],
  #                  yerr=dataset["errors"], c=dataset["color"],
  #                  linestyle=dataset["linestyle"],
  #                  label=dataset["name"], ecolor="k", capthick=1)
  # ax = plt.gca()

  # # No legend title
  # plt.legend(loc='upper left right')
  # ax.get_legend().set_title("")
  # ax.get_legend().draw_frame(True)

  # plt.xlim(stepMin, stepMax)
  # plt.ylim(0, )

  # if LOG_SCALE:
  #     ax.set_xscale("log", nonposy='clip')

  # plt.xlabel("#. kernels")
  # plt.ylabel("#. close kernels")

  # figsize = (4.5, 2.15)
  # viz.finalise(fs.path("~/cgo17/img/closer-than.pdf"), figsize=figsize)


def exp_range(start, end, mul):
  while start < end:
    yield start
    start *= mul
  yield end


def main():
  # closeness("A")
  # closeness("B")

  # static_kernel_closeness()
  zero_distance()
  # closer_than()


if __name__ == "__main__":
  main()
