#!/usr/bin/env python3
#
import re
import sys
from itertools import combinations

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from numpy.random import RandomState
from sklearn.base import clone
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier

from labm8 import viz


# Seaborn configuration:
sns.set(style="ticks", color_codes=True)
plt.style.use(["seaborn-white", "seaborn-paper"])


def get_cgo13_model():
  # return KNeighborsClassifier(1)
  return DecisionTreeClassifier(
      random_state=204,
      splitter="best",
      criterion="entropy",
      # max_depth=4,
      # min_samples_split=6,
      # min_samples_leaf=3
  )


def get_cgo13_features(D):
  return np.array([
    (D["transfer"].values / (D["comp"].values + D["mem"].values)),
    (D["coalesced"].values / D["mem"].values),
    ((D["localmem"].values / D["mem"].values) * D["wgsize"].values),
    (D["comp"].values / D["mem"].values),
  ]).T


def get_our_model():
  return KNeighborsClassifier(1)
  # return SVC(kernel="linear", C=0.025)
  # return SVC(gamma=2, C=1)
  # return RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)
  # return AdaBoostClassifier()
  # return GaussianNB()
  # return LinearDiscriminantAnalysis()
  # return QuadraticDiscriminantAnalysis()
  # return DecisionTreeClassifier(
  #     random_state=204, criterion="entropy", splitter="best")


def get_our_features(D):
  return np.array([
    D["comp"].values,
    D["rational"].values,
    D["mem"].values,
    D["localmem"].values,
    D["coalesced"].values,
    D["atomic"].values,
    D["transfer"].values,
    D["wgsize"].values,
    (D["transfer"].values / (D["comp"].values + D["mem"].values)),
    (D["coalesced"].values / D["mem"].values),
    ((D["localmem"].values / D["mem"].values) * D["wgsize"].values),
    (D["comp"].values / D["mem"].values),
  ]).T


def get_raw_features(D):
  return np.array([
    D["comp"].values,
    D["rational"].values,
    D["mem"].values,
    D["localmem"].values,
    D["coalesced"].values,
    D["atomic"].values,
    D["transfer"].values,
    D["wgsize"].values,
  ]).T


def get_labels(D):
  return D["oracle"]


def customaxis(ax, c_left='k', c_bottom='k', c_right='none', c_top='none',
               lw=1, size=12, pad=8):
  """
  Credit: http://stackoverflow.com/a/11417222
  """
  for c_spine, spine in zip([c_left, c_bottom, c_right, c_top],
                            ['left', 'bottom', 'right', 'top']):
    if c_spine != 'none':
      ax.spines[spine].set_color(c_spine)
      ax.spines[spine].set_linewidth(lw)
    else:
      ax.spines[spine].set_color('none')
  if (c_bottom == 'none') & (c_top == 'none'):  # no bottom and no top
    ax.xaxis.set_ticks_position('none')
  elif (c_bottom != 'none') & (c_top != 'none'):  # bottom and top
    ax.tick_params(axis='x', direction='out', width=lw, length=7,
                   color=c_bottom, labelsize=size, pad=pad)
  elif (c_bottom != 'none') & (c_top == 'none'):  # bottom but not top
    ax.xaxis.set_ticks_position('bottom')
    ax.tick_params(axis='x', direction='out', width=lw, length=7,
                   color=c_bottom, labelsize=size, pad=pad)
  elif (c_bottom == 'none') & (c_top != 'none'):  # no bottom but top
    ax.xaxis.set_ticks_position('top')
    ax.tick_params(axis='x', direction='out', width=lw, length=7,
                   color=c_top, labelsize=size, pad=pad)
  if (c_left == 'none') & (c_right == 'none'):  # no left and no right
    ax.yaxis.set_ticks_position('none')
  elif (c_left != 'none') & (c_right != 'none'):  # left and right
    ax.tick_params(axis='y', direction='out', width=lw, length=7,
                   color=c_left, labelsize=size, pad=pad)
  elif (c_left != 'none') & (c_right == 'none'):  # left but not right
    ax.yaxis.set_ticks_position('left')
    ax.tick_params(axis='y', direction='out', width=lw, length=7,
                   color=c_left, labelsize=size, pad=pad)
  elif (c_left == 'none') & (c_right != 'none'):  # no left but right
    ax.yaxis.set_ticks_position('right')
    ax.tick_params(axis='y', direction='out', width=lw, length=7,
                   color=c_right, labelsize=size, pad=pad)


def leave_one_benchmark_out(clf, get_features, D, benchmark):
  # Create data masks. For training we exclude all results from
  # the test benchmark.
  test_mask = D["benchmark"].str.contains(r"^" + benchmark)
  train_mask = ~test_mask

  # Create training and testing data:
  X_train = get_features(D[train_mask])
  y_train = get_labels(D[train_mask])

  D_test = D[test_mask]
  X_test = get_features(D_test)
  y_test = get_labels(D_test)

  # Train classifier:
  clf.fit(X_train, y_train)

  # Make predictions
  predicted = clf.predict(X_test)
  D_out = []
  for d, y, p in zip(D_test.to_dict('records'), y_test, predicted):
    d["p"] = p
    d["p_correct"] = 1 if y == p else 0
    D_out.append(d)

  # Return a list of dicts
  return D_out


def rand_jitter(arr, factor=0.01, randomstate=RandomState(204)):
  stdev = factor * (max(arr) - min(arr))
  return arr + randomstate.randn(len(arr)) * stdev


def scatter_with_jitter(plt, x, y, **kwargs):
  jitter_opts = kwargs.get("jitter_opts", {})
  if "jitter_opts" in kwargs: kwargs.pop("jitter_opts")

  jitter_factor = kwargs.get("jitter", None)
  if jitter_factor is not None:
    jitter_opts["factor"] = jitter_factor
    kwargs.pop("jitter")

  return plt.scatter(rand_jitter(x, **jitter_opts),
                     rand_jitter(y, **jitter_opts), **kwargs)


counter = 0


def check_for_subset(candidates):
  global counter
  counter += 1
  print("\r\033[Ktest #.", counter, end="")
  sys.stdout.flush()

  clf = get_cgo13_model()
  platform = "b"
  suite = "parboil"

  # Load data and mask off the benchmark suite in use:

  # Scatter type:
  opts = {"s": 85, "alpha": .65}

  # Reset classifier
  clf = clone(clf)

  # Load data and mask off the benchmark suite in use:
  B = pd.read_csv("data/{}/benchmarks.csv".format(platform))
  S = pd.read_csv("data/{}/synthetics.csv".format(platform))
  BS = pd.concat((B, S))

  train_mask = BS["benchmark"].str.contains(r"^" + suite + "|" +
                                            "|".join(candidates))
  test_mask = BS["benchmark"].str.contains(r"^" + suite)
  other_mask = BS["benchmark"].str.contains("|".join(candidates))

  Btrain = BS[train_mask]
  Btest = BS[test_mask]
  Bother = BS[other_mask]
  assert (len(Bother) + len(Btest) == len(Btrain))

  benchmark_names = sorted(set([
    re.match(r"^([^0-9]+-[0-9\.]+-[^-]+)-", b).group(1)
    for b in B["benchmark"] if b.startswith(suite)
  ]))

  B_out = []
  for benchmark in benchmark_names:
    B_out += leave_one_benchmark_out(clf, get_cgo13_features, Btrain,
                                     benchmark)
  B_out = pd.DataFrame(B_out)
  assert (len(Btest) == len(B_out))

  num_incorrect = len(B_out) - sum(B_out["p_correct"])
  if num_incorrect > 3:
    return

  jitter = .05
  pca = PCA(n_components=2)
  pca.fit(get_raw_features(Btrain))
  X = pca.transform(get_raw_features(Btest))

  # Apply jitter
  x, y = zip(*X)
  x = rand_jitter(x, jitter, RandomState(204))
  y = rand_jitter(y, jitter, RandomState(205))
  X = list(zip(x, y))

  correct = [
    x for x, b in zip(X, B_out.to_dict('records')) if b["p_correct"]]
  incorrect = [
    x for x, b in zip(X, B_out.to_dict('records')) if not b["p_correct"]]

  other = pca.transform(get_raw_features(Bother))

  scatter_with_jitter(plt, *zip(*other), color="g", label='Correct',
                      jitter=jitter, **opts)
  plt.scatter(*zip(*incorrect), color="r", label='Incorrect', **opts)
  plt.scatter(*zip(*correct), color="b", label='Correct', **opts)

  ax = plt.gca()
  # No ticks
  ax.xaxis.set_major_locator(plt.NullLocator())
  ax.yaxis.set_major_locator(plt.NullLocator())

  # Axis labels
  plt.xlabel("e1 →", ha="right")
  plt.ylabel("e2 →", ha="right")

  # Position axis labels at end of axis
  ax.xaxis.set_label_coords(1, -.025)
  ax.yaxis.set_label_coords(-.025, 1)

  # Show legend
  # handles, labels = ax.get_legend_handles_labels()
  # ax.legend(handles, labels)
  # ax.get_legend().draw_frame(True)

  # Set same axis limits as before

  figsize = (2.5, 2.5)

  with open("motivation-{}-{}-{}.txt".format(num_incorrect, len(candidates),
                                             counter), "w") as outfile:
    print("\n".join(candidates), file=outfile)

  viz.finalise("motivation-{}-{}-{}.png".format(num_incorrect,
                                                len(candidates), counter),
               figsize=figsize)


def main():
  S = pd.read_csv("data/b/benchmarks.csv")
  # Smask = ~S["benchmark"].str.contains("parboil")
  Smask = S["benchmark"].str.contains("shoc")
  candidates = sorted(set(S[Smask]["benchmark"]))

  for n in range(1, 10):
    print()
    print("Trying all combinations of", n, "additions")
    for combination in combinations(candidates, n):
      check_for_subset(combination)
  print("Best results:", best, best_combination)


if __name__ == "__main__":
  main()
