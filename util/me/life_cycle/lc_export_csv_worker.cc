// Process a Life Cycle CSV file and extract series.
//
// LifeCycle exports data as comma separated values with the following schema:
//
//     START DATE(UTC)     Datetime encoded in "%Y-%m-%d %H:%M%S" format.
//     END DATE(UTC)       Datetime encoded in "%Y-%m-%d %H:%M%S" format.
//     START TIME(LOCAL)   Datetime encoded in "%Y-%m-%d %H:%M%S %Z" format.
//     END TIME(LOCAL)     Datetime encoded in "%Y-%m-%d %H:%M%S %Z" format.
//     DURATION            The difference between start and end time in seconds.
//     NAME (optional)     The "What did you do?" category name.
//     LOCATION (optional) The "Where were you?" location name.
//     NOTE (optional)     The contents of the "notes" field.
//
// For the three optional columns, if no value is present, the field is empty.
// The file begins with a header containing the 8 columns names, then an empty
// line.
//
// Lines are delimited using Windows-style '\r\n' returns.
//
// From what I can see, there is no quoting in the CSV, but I haven't tested
// what happens if if NAME/LOCATION/NOTE fields contain commas.
//
// The "START DATE" and "END DATE" for entries can be on different dates.
//
// The SeriesCollection generated by this program contains one series for each
// NAME. The following schema is used:
//
//     Series.name        "${NAME}Time"
//     Series.family      "TimeTracking"
//     Series.unit        "milliseconds"
//     Measurement.group  "${LOCATION}", if set, else "default"
//     Measurement.ms_since_unix_epoch  The START DATE (see below).
//     Measurement.value  END DATE - START DATE in milliseconds (see below).
//     Measurement.source "LifeCycle"
//
// The NOTE field is not exported.
//
// If entry has a start date different from the end date, it is split into
// multiple Measurements, one per day. This means that summing the measurements
// for a day is always <= 24 hours.
//
#include "phd/macros.h"
#include "phd/pbutil.h"
#include "phd/string.h"

#include "util/me/me.pb.h"

#include "absl/strings/str_cat.h"
#include "absl/strings/str_split.h"
#include "absl/time/time.h"
#include "absl/container/flat_hash_map.h"

#include <boost/filesystem.hpp>
#include <boost/filesystem/fstream.hpp>

namespace me {

namespace {

// The number of milliseconds in a day.
constexpr int64_t MILLISECONDS_IN_DAY =
    /*second=*/1000 * /*hour=*/3600 * /*day=*/24;

// Round a timestamp, as milliseconds since the epoch in UTC, up to the "zeroth"
// millisecond of the next day.
int64_t RoundToStartOfNextDay(const int64_t ms_since_unix_epoch) {
  // Divide by milliseconds in day to produce the number of days elapsed since
  // epoch. Since this is integer division, this rounds down.
  const int64_t days_since_epoch_utc =
      ms_since_unix_epoch / MILLISECONDS_IN_DAY;

  // Add one to day count and multiply back to milliseconds.
  return (days_since_epoch_utc + 1) * MILLISECONDS_IN_DAY;
}


template<typename K, typename V>
V FindOrAdd(absl::flat_hash_map<K, V>* map, const K& key,
            std::function<V(const K&)> add_callback) {
  auto it = map->find(key);

  if (it == map->end()) {
    return add_callback(key);
  } else {
    return it->second;
  }
}


// Parse a (START|END)_DATE or (START|END)_TIME column to an absl::Time
// instance, or fatally error.
absl::Time ParseLifeCycleDatetimeOrDie(const string& date) {
  absl::Time time;
  std::string err;
  bool succeeded = absl::ParseTime("%Y-%m-%d %H:%M:%S", date, &time, &err);
  if (!succeeded) {
    FATAL("Failed to parse '%s': %s", date, err);
  }
  return time;
}

// Convert an absl::Time instance to the number of milliseconds since the Unix
// epoch.
int64_t ToMillisecondsSinceUnixEpoch(const absl::Time& time) {
  absl::Duration d = time - absl::UnixEpoch();
  return d / absl::Milliseconds(1);
}


string LocationToGroup(const string& location) {
  if (location.empty()) {
    return "default";
  } else {
    return phd::ToCamelCase(location);
  }
}

// Process a line from a LifeCycle CSV file and add Measurement(s) to Series
// map. Each line produces one or more Measurements.
void ProcessLineAndAddMeasurementsOrDie(
    const std::string& line, const int64_t line_num,
    const boost::filesystem::path csv_path, SeriesCollection* const proto,
    absl::flat_hash_map<string, Series*>* const name_to_series_map) {
  // Split the comma separated line.
  std::vector<absl::string_view> components = absl::StrSplit(line, ',');
  if (components.size() < 8) {
    FATAL("Line %d of `%s` does not have 8 columns: '%s'",
          line_num, csv_path.string(), line);
  }

  // Split out the variables from the line.
  const string start_date_str = string(components[0]);
  const string end_date_str = string(components[1]);
  const string name = phd::TrimLeftCopy(string(components[5]));
  const string location = LocationToGroup(
      phd::TrimLeftCopy(string(components[6])));

  // Find the series that the measurements should belong to. If the Series
  // does not exist, create it.
  Series* series = FindOrAdd<string, Series*>(
      name_to_series_map, name,
      [name_to_series_map,proto](const string& name) -> Series* {
    Series* series = proto->add_series();
    series->set_name(absl::StrCat(phd::ToCamelCase(name), "Time"));
    series->set_family("TimeTracking");
    series->set_unit("milliseconds");
    name_to_series_map->insert(
        std::make_pair(name, series));
    return series;
  });

  // Parse the timestamps.
  int64_t start_time = ToMillisecondsSinceUnixEpoch(
    ParseLifeCycleDatetimeOrDie(start_date_str));
  const int64_t end_time = ToMillisecondsSinceUnixEpoch(
    ParseLifeCycleDatetimeOrDie(end_date_str));
  CHECK(start_time);
  CHECK(end_time);

  // Create measurements for the duration. If the duration overflows to
  // subsequent dates, it is split into multiple Measurements, one per day.
  // This means that summing the measurements for a day is always <= 24 hours.
  int64_t remaining_time_to_allocate = end_time - start_time;
  int64_t end_of_day = RoundToStartOfNextDay(start_time);

  while (remaining_time_to_allocate > 0) {
    int64_t duration = std::min(remaining_time_to_allocate, end_of_day);

    // Create the new measurement.
    Measurement* measurement = series->add_measurement();
    measurement->set_ms_since_unix_epoch(start_time);
    measurement->set_value(duration);
    measurement->set_group(location);
    measurement->set_source("LifeCycle");

    start_time = end_of_day;
    remaining_time_to_allocate -= MILLISECONDS_IN_DAY;
    end_of_day += MILLISECONDS_IN_DAY;
  }
}

}  // namespace

void ProcessLcExportCsv(SeriesCollection* proto) {
  const boost::filesystem::path csv_path(proto->source());

  CHECK(boost::filesystem::is_regular_file(csv_path));
  INFO("Reading from CSV file %s", csv_path.string());

  boost::filesystem::ifstream csv(csv_path);
  CHECK(csv.is_open());

  string line;
  // Process the first line of the header.
  std::getline(csv, line);
  if (line != ("START DATE(UTC), END DATE(UTC), START TIME(LOCAL), "
               "END TIME(LOCAL), DURATION, NAME, LOCATION, NOTE")) {
    FATAL("Expected first line of `%s` to contain column names. Actual "
          "value: `%s`.", csv_path.string(), line);
  }

  // Process the second line of the header.
  std::getline(csv, line);
  if (line == "\n") {
    FATAL("Expected second line of `%s` to be empty. Actual value: `%s`",
          csv_path.string(), line);
  }

  // Keep a map from name columns to series. Measurements are assigned to named
  // Series. We use this map to determine which Series to add each Measurement
  // to.
  absl::flat_hash_map<string, Series*> name_to_series_map;

  // Iterate through the file.
  int line_num = 2;  // We skipped the first two lines.
  while (std::getline(csv, line)) {
    ++line_num;
    ProcessLineAndAddMeasurementsOrDie(line, line_num, csv_path, proto,
                                       &name_to_series_map);
  }
}

}  // namespace me

PBUTIL_INPLACE_PROCESS_MAIN(me::ProcessLcExportCsv, me::SeriesCollection);
