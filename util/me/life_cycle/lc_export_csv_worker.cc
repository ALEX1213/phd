// Process a Life Cycle CSV file and extract series.
//
// LifeCycle exports data as comma separated values with the following schema:
//
//     START DATE(UTC)     Datetime encoded in "%Y-%m-%d %H:%M%S" format.
//     END DATE(UTC)       Datetime encoded in "%Y-%m-%d %H:%M%S" format.
//     START TIME(LOCAL)   Datetime encoded in "%Y-%m-%d %H:%M%S %Z" format.
//     END TIME(LOCAL)     Datetime encoded in "%Y-%m-%d %H:%M%S %Z" format.
//     DURATION            The difference between start and end time in seconds.
//     NAME (optional)     The "What did you do?" category name.
//     LOCATION (optional) The "Where were you?" location name.
//     NOTE (optional)     The contents of the "notes" field.
//
// For the three optional columns, if no value is present, the field is empty.
// The file begins with a header containing the 8 columns names, then an empty
// line.
//
// Lines are delimited using Windows-style '\r\n' returns.
//
// From what I can see, there is no quoting in the CSV, but I haven't tested
// what happens if if NAME/LOCATION/NOTE fields contain commas.
//
// The "START DATE" and "END DATE" for entries can be on different dates.
//
// The SeriesCollection generated by this program contains one series for each
// NAME. The following schema is used:
//
//     Series.name        "${NAME}Time"
//     Series.family      "TimeTracking"
//     Series.unit        "milliseconds"
//     Measurement.group  "${LOCATION}", if set, else "default"
//     Measurement.ms_since_epoch_utc  UTC encoded START DATE.
//     Measurement.value  END DATE* - START DATE in milliseconds.
//     Measurement.source "LifeCycle"
//
// The NOTE field is not exported.
//
// TODO(cec): If an entry overflows to subsequent dates it should be split into
// multiple Measurements, one per day. Currently, measurements are allowed to
// overflow the day boundary, meaning that sum of all measurements for a day
// can be > 24 hours.
//
#include "phd/macros.h"
#include "phd/pbutil.h"
#include "phd/string.h"

#include "util/me/me.pb.h"

#include "absl/strings/str_cat.h"
#include "absl/strings/str_split.h"
#include "absl/time/time.h"
#include "absl/container/flat_hash_map.h"

#include <boost/filesystem.hpp>
#include <boost/filesystem/fstream.hpp>

namespace me {

template<typename K, typename V>
V FindOrAdd(absl::flat_hash_map<K, V>* map, const K& key,
            std::function<V(const K&)> add_callback) {
  auto it = map->find(key);

  if (it == map->end()) {
    return add_callback(key);
  } else {
    return it->second;
  }
}


int64_t ParseTimeOrDie(const string& date) {
  absl::Time time;
  std::string err;
  bool succeeded = absl::ParseTime("%Y-%m-%d %H:%M:%S", date, &time, &err);
  if (!succeeded) {
    FATAL("Failed to parse '%s': %s", date, err);
  }
  absl::Duration d = time - absl::UnixEpoch();
  return d / absl::Milliseconds(1);
}


void ProcessLcExportCsv(SeriesCollection* proto) {
  const boost::filesystem::path csv_path(proto->source());

  CHECK(boost::filesystem::is_regular_file(csv_path));
  INFO("Reading from CSV file %s", csv_path.string());

  boost::filesystem::ifstream csv(csv_path);
  CHECK(csv.is_open());

  string line;
  // Skip the first line which is the header.
  std::getline(csv, line);
  // Skip the second line, which should be empty.
  std::getline(csv, line);
  CHECK(phd::TrimRightCopy(line).empty());

  // Keep a map from name columns to series. Measurements are assigned to named
  // Series. We use this map to determine which Series to add each Measurement
  // to.
  absl::flat_hash_map<string, Series*> name_to_series_map;

  // Iterate through the file.
  int line_num = 2;  // We skipped the first two lines.
  while (std::getline(csv, line)) {
    ++line_num;
    // Split the comma separated line.
    std::vector<absl::string_view> components = absl::StrSplit(line, ',');
    if (components.size() < 8) {
      FATAL("Line %d of %s does not have 8 columns: '%s'",
            line_num, csv_path.string(), line);
    }

    // Split out the variables from the line.
    const string start_date_str = string(components[0]);
    const string end_date_str = string(components[1]);
    const string name = phd::TrimCopy(string(components[5]));
    const string location = phd::TrimCopy(string(components[6]));

    // Parse the timestamps.
    int64_t start_time = ParseTimeOrDie(start_date_str);
    int64_t end_time = ParseTimeOrDie(end_date_str);
    CHECK(start_time);
    CHECK(end_time);

    // Find the series that the new measurement should belong to. If the Series
    // does not exist, create it.
    Series* series = FindOrAdd<string, Series*>(
        &name_to_series_map, name,
        [&name_to_series_map,proto](const string& name) -> Series* {
      Series* series = proto->add_series();
      series->set_name(absl::StrCat(phd::ToCamelCase(name), "Time"));
      series->set_family("TimeTracking");
      series->set_unit("milliseconds");
      name_to_series_map.insert(
          std::make_pair(name, series));
      return series;
    });

    // Create the new measurement.
    Measurement* measurement = series->add_measurement();
    measurement->set_ms_since_epoch_utc(start_time);
    measurement->set_value(end_time - start_time);
    if (location.empty()) {
      measurement->set_group("default");
    } else {
      measurement->set_group(phd::ToCamelCase(location));
    }
    measurement->set_source("LifeCycle");
  }
}

}  // namespace me

PBUTIL_INPLACE_PROCESS_MAIN(me::ProcessLcExportCsv, me::SeriesCollection);
