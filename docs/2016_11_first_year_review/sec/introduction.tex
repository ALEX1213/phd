\section{Introduction}

%Tuning parallel programs is hard, and consumes untold man-hours of labour. The automation of this task is a much sought after goal, but current approaches are ad-hoc, impractical, and unable to generalize across the broad space of hardware and software. Developers are no longer able to rely on increasing clock speeds to increase the performance of their programs, and must instead rely on parallelisation using an increasingly exotic range of heterogeneous architectures and accelerators. The shape of this landscape is changing faster than developers' ability to tune for it. A more robust technique that is capable of automatically tuning parallel programs is required in order to
%
%The physical limitations of microprocessor design have forced the industry towards increasingly heterogeneous designs to extract performance, with an an increasing pressure to offload traditionally CPU based workloads to the GPU. This trend has not been matched with adequate software tools; the popular languages OpenCL and CUDA provide a very low level model with little abstraction above the hardware. Programming at this level requires expert knowledge of both the domain and the target hardware, and achieving performance requires laborious hand tuning of each program. This has led to a growing disparity between the availability of parallelism in modern hardware, and the ability for application developers to exploit it.
%
%The goal of this work is to bring the performance of hand tuned heterogeneous code to high level programming, by incorporating autotuning into \textit{Algorithmic Skeletons}. Algorithmic Skeletons simplify parallel programming by providing reusable, high-level, patterns of computation. However, achieving performant skeleton implementations is a difficult task; skeleton authors must attempt to anticipate and tune for a wide range of architectures and use cases. This results in implementations that target the general case and cannot provide the performance advantages that are gained from tuning low level optimization parameters for individual programs and architectures. Autotuning combined with machine learning offers promising performance benefits by tailoring parameter values to individual cases, but the high cost of training and the ad-hoc nature of autotuning tools limits the practicality of autotuning for real world programming. We believe that performing autotuning at the level of the skeleton library can overcome these issues.

\subsection{Project aim}

The aim of this project is the development of novel deep learning methods for the automatic generation of programs, with applications for improving predictive modelling and testing methods for compilers. The automatic generation of programs benefits predictive modelling if the generated programs enumerate a given program feature space, providing useful benchmarks for learning optimisation heuristics. In compiler testing, the automatic generation of programs is beneficial if there are programs produced whose computed results differ between compiler implementations.

Current approaches to program generation are limited to random instantiation of code templates and datasets, or inflexible formal grammar methods. These methods typically produce programs which are markedly unlike real hand-written programs. This limits their utility for predictive modelling and compiler testing --- programs which do not resemble hand-written code may expose bugs in compilers which are not considered a priority to address; and, given their unusual nature, may fail to enumerate the parts of program feature spaces which are relevant to real human workloads.

The aim of my work is to develop a new approach to program generation, in which a stream of program fragments taken from open source code are analysed at large scale and used to build probabilistic language models from which new programs can be sampled. In modelling real hand written codes, these generated programs will be indistinguishable from human workloads, and will allow enumeration of the relevant part of program feature spaces, as well as identifying bugs in compilers which arise from common usage of a programming language.


\subsection{Project objectives}\label{sec:objectives}

\begin{enumerate}
  \item \emph{A system for automatic program generation through deep learning}. At its simplest, such a system would consist of a method for generating program code, and a tool for checking whether a given program is syntactically and semantically correct and executable. The foundation for developing this system is the application of language modelling to large corpuses of open source code, with the intent of learning not just the syntax and semantics of a particular programming language, but also the patterns and traits of programs which are most representative of real human workloads. The goal of this objective is the automatic generation of human-like workloads.
  \item \emph{A technique for the generation of programs which match a given property of interest.} Properties of interest could include: having static code features within a given range; computing different outputs when compiled using different compilers; or exceeding a minimum threshold of runtime on a particular architecture. This extension to the previous objective will allow for a directed exploration of a program feature space.
  \item \emph{An agent-based approach for per-program selection and ordering of compiler optimisation passes using reinforcement learning.} Both compiler optimisation pass selection and phase ordering are critical to the effectiveness of optimising compilers, and are difficult problems to tackle. Fixed phase orderings fail to exploit the available performance on a per-program basis, and the optimisation spaces are large and high dimensional, rendering exhaustive search infeasible. As a demonstration of the effectiveness of automatic program generation, the fixed phase ordering of a compiler may be replaced with an agent which would enable online tuning of the optimisation pipeline, using automatically generated programs to explore the high dimensional optimisation space.
  \item \emph{Dissemination of results in one or more top-tier conference or journal}. Each of the previously described objectives corresponds to one or more potential publications. Relevant conferences and journals to target for publication include: CGO, FSE, HiPC, ICPP, IJPP, LCTES, OOPSLA, PACT, PLDI, PPoPP, and TACO.
\end{enumerate}


%\subsection{Research impact}
%
%\paragraph{Iterative compilation} ML requires lots of benchmarks.
%
%
%\paragraph{Compiler testing} CSmith is successful. XSmith is a thing.
