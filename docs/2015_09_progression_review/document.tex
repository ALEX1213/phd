% A two page document describing lessons learned from the project, the
% revised PhD vision and insights, and a plan of activities for the
% next three months
%
\documentclass[11pt]{article}

\author{Chris Cummins}
\date{September 2015}
\title{PhD Progression Review: Autotuning\\and Skeleton-aware Compilation}

\input{preamble}

\begin{document}

  \begin{center}
    \Large
    \textbf{PhD Progression Review: Autotuning\\and Skeleton-aware Compilation}
    \vspace{0.2cm}

    \normalsize
    Chris Cummins\\
    September 2015
    \vspace{0.2cm}
  \end{center}
  %\maketitle

  \begin{abstract}
    \noindent
    I present a research proposal to develop an optimising compiler
    specifically tailored for algorithmic skeletons. Such a compiler would
    be capable of performing optimisations which are not possible by
    library-level skeleton frameworks: optimisations across skeleton calls
    (e.g.\ to re-order the execution of nested skeletons), and across
    muscle functions (e.g.\ to perform load balancing of pipeline
    stages). This document briefly outlines the proposed project, and
    summarises the findings from the MSc phase of my CDT.
  \end{abstract}

  \section{Introduction}

  In my initial CDT application, I postulated that in order to address
  the under-utilisation of parallel resources that is a symptom of the
  modern hardware/software ecosystem, the goal should be to move towards
  \emph{automated} parallelism. My MSc thesis worked towards this goal
  by developing a system for adaptive tuning of patterns (algorithmic
  skeletons) for high level parallel programming. Skeletons provide
  abstractions that free developers from the concerns of managing
  parallel resources. The need for adaptive tuning of skeletons was
  demonstrated by the significant performance improvements which were
  achieved through autotuning of only a single two-dimensional parameter
  space for stencil skeletons. I demonstrated a median geometric speedup
  of $3.79\times$ across benchmarks from both real world and
  synthetically generated sources. My intention over the coming months
  is to broaden the scope of this work to consider the interaction
  between algorithmic skeletons and optimising compilers.

  % The first year of this CDT was spent investigating autotuning
  % algorithmic skeletons for stencil codes on CPUs and GPUs. This was a
  % challenging but rewarding project which providing me with a
  % grounding in research approaches to high level parallel programming,
  % GPU parallelism, autotuning, and machine learning. In this document
  % I critically evaluate my work during this MSc phase, and propose a
  % direction for future research which builds upon the knowledge and
  % skills acquired in the first year, while addressing the challenges I
  % faced.

  % The broad scope of the proposal for my initial application was to
  % address the parallel programmability challenge, by enabling a shift
  % towards automatic parallelism. During my first three months the scope
  % of this proposal was adjusted to focus on improving the high level
  % parallel programming by adaptive tuning. To this end, my MSc thesis
  % investigated adaptive tuning of a parameter space for skeletal
  % programming. It is my intention to continue working towards this goal
  % by focusing next on the interaction between compilers and algorithmic
  % skeletons.

  % Iâ€™ve shown that the optimisation space of a fixed implementation can
  % be successfully tuned using machine learning. The next step is to
  % combine these techniques with an understanding of optimising
  % compilers in order to generate adaptive implementations.


  \section{MSc Phase Review}

  My MSc thesis introduced \textit{OmniTune}, a framework for runtime
  autotuning of parameters. The effectiveness of this approach was
  demonstrated using the workgroup size of stencil skeletons for CPUs
  and GPUs. Machine learning models trained using data collected from
  synthetically generated benchmarks were evaluated for prediction
  quality in this two-dimensional parameter space.

  The plan for the project consisted of three sequential phases:
  identifying a profitable optimisation space, probing the space to
  gather empirical performance data, and developing a system to exploit
  this optimisation space. In reality, there was a great overlap between
  the progress of each phase: identifying the optimisation space was
  achieved using empirical performance data, and in turn gathering
  performance data required the partial development of the autotuning
  system. Broadly, the stencil optimisations space had been identified
  by early March, the collection of empirical performance data began in
  mid April, and the development of the final OmniTune autotuning system
  began in mid May. For future work, a methodology based upon shorter,
  iterative cycles of testing, implementing, and evaluating should be
  used. This should also be coupled with regular write-ups of current
  findings and results, in addition to the logbook I kept this
  year. Another insight which can be transferred to future work is the
  importance of clear, testable hypotheses, which should be identified
  during early planning
  stages. % All source code and notes were hosted publicly on GitHub.

  % - short development cycles, with milestones and reviews at each stage
  %
  % - a more clearly testable hypothesis - i.e. a less vague project plan


  \section{%Beginning the
  PhD Phase}

  While the tuning of parameter values demonstrably has a significant
  impact on the performance of skeleton programs, there is great scope
  for optimisation at the compilation stage. The complexity of parallel
  programs restricts the number of optimisations which compilers may
  apply, and furthermore there are higher-level restructurings and
  implementation choices which could be made by compilers equipped with
  an understanding of the semantics of skeleton operations.

  \subsection{Objectives}

  The objective of compiler research for algorithmic skeletons would be
  to enable ``skeleton-aware compilation''. This can be considered both
  as the enabling of existing compiler optimisations to algorithmic
  skeletons which cannot currently be applied due to limitations in the
  static analysis of parallel programs, and the development of novel
  optimisations which are specific to algorithmic skeletons. In both
  cases, skeleton-aware compilation will be able to provide measurable
  performance improvements of programs compiled using the existing state
  of the art in optimising compilers.


  \subsection{Methodology}

  This research project will begin with an exposition of the relevant
  literature to help enumerate the range of possible optimisations which
  could be applied, and to identify what has already been achieved.
  When identifying a range of optimisations which could be developed,
  low cost proof-of-concept tests can be performed for each by manually
  performing an optimisation by hand for a specific benchmark and
  gathering empirical performance data. If the optimisation leads to
  measurable performance improvements, a transformation pass in a
  relevant compiler (e.g.\ LLVM) can be implemented to automatically
  apply this optimisation. Test programs may be selected from existing
  benchmark suites (e.g. the Intel Thread Building Blocks port of
  PARSEC), or by using synthetically generated programs, perhaps by
  extending the benchmark generator developed for my MSc project. In
  case of optimisations for which the potential benefit cannot
  statically be determined (e.g.\ load balancing between stages of a
  pipeline), the OmniTune framework may be extended to provide
  autotuning capabilities for the space of possible optimisations.


  \section{Summary}

  In my first year I have demonstrated the importance of adaptive tuning
  for maximising the performance of high level parallel patterns. I
  intend to continue improving the performance of high level parallel
  patterns, but taking an approach from the level of the compiler, with
  the aim of developing skeleton-aware compilation. The skills I
  acquired this year in skeletal programming, heterogeneous parallelism,
  machine learning, and autotuning will all be required for achieving
  this aim. The success of the project can be quantifiably measured in
  terms of performance improvements to real world skeleton programs.


  \label{bibliography}
  \printbibliography

\end{document}
